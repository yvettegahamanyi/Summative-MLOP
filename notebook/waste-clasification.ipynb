{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5372285f",
   "metadata": {},
   "source": [
    "# Waste Classification with EfficientNetB0\n",
    "\n",
    "This notebook builds an end-to-end image classification pipeline for multi-class waste sorting using EfficientNetB0. It covers data acquisition from Google Drive, preprocessing, training with regularization and optimization callbacks, and model evaluation/testing with multiple metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262c24d8",
   "metadata": {},
   "source": [
    "## Workflow Overview\n",
    "\n",
    "1. **Data acquisition** – Mount Google Drive (or download) and set dataset paths.\n",
    "2. **Data preprocessing** – Build TensorFlow datasets with augmentation, batching, caching, and normalization.\n",
    "3. **Model creation** – Fine-tune EfficientNetB0 with dropout, L2 regularization, Adam optimizer, and learning-rate scheduling. Save the best model as `.h5`.\n",
    "4. **Model evaluation** – Report loss, accuracy, precision, recall, F1, confusion matrix, and classification report on validation/test sets.\n",
    "5. **Model testing** – Run single-image inference utilities for manual inspection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Global config\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_context(\"talk\", font_scale=0.9)\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-3\n",
    "DROPOUT_RATE = 0.2\n",
    "L2_REG = 1e-4\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcc8e03",
   "metadata": {},
   "source": [
    "## Data Acquisition\n",
    "\n",
    "The dataset lives on Google Drive with class-specific folders:\n",
    "\n",
    "- `Cardboard`, `Food Organics`, `Glass`, `Metal`, `Miscellaneous Trash`, `Paper`, `Plastic`, `Textile Trash`, `Vegetation`\n",
    "\n",
    "Each folder should contain JPEG/PNG images. Update the `DRIVE_DATASET_PATH` below to point to the root directory that holds these class folders (or to a parent directory containing `train`, `val`, and `test` splits).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive when running in Google Colab (safe to skip elsewhere)\n",
    "try:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount(\"/content/drive\", force_remount=True)\n",
    "    DEFAULT_DATASET_PATH = \"/content/drive/MyDrive/datasets/waste\"\n",
    "    DEFAULT_MODEL_DIR = \"/content/drive/MyDrive/experiments/waste\"\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Running outside Google Colab. Skipping Drive mount.\")\n",
    "    DEFAULT_DATASET_PATH = \"/path/to/local/waste-dataset\"\n",
    "    DEFAULT_MODEL_DIR = \"./models\"\n",
    "\n",
    "DATASET_ROOT = Path(os.getenv(\"WASTE_DATASET_PATH\", DEFAULT_DATASET_PATH))\n",
    "MODEL_DIR = Path(os.getenv(\"WASTE_MODEL_DIR\", DEFAULT_MODEL_DIR))\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_PATH = MODEL_DIR / \"efficientnetb0_waste_classifier.h5\"\n",
    "DATASET_ROOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if not DATASET_ROOT.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset path {DATASET_ROOT} was not found. Set WASTE_DATASET_PATH env variable or update DEFAULT_DATASET_PATH.\"\n",
    "    )\n",
    "\n",
    "class_names = sorted([entry.name for entry in DATASET_ROOT.iterdir() if entry.is_dir()])\n",
    "print(f\"Found {len(class_names)} classes:\")\n",
    "for name in class_names:\n",
    "    num_files = len(list((DATASET_ROOT / name).glob(\"*.jpg\"))) + len(list((DATASET_ROOT / name).glob(\"*.png\")))\n",
    "    print(f\" - {name}: ~{num_files} images (jpg/png)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2223fdd2",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "We create TensorFlow datasets directly from the directory tree, applying:\n",
    "\n",
    "- stratified split (70% train, 15% validation, 15% test) using a deterministic seed\n",
    "- on-the-fly augmentation: random flip, rotation, color jitter\n",
    "- batching, caching, shuffling, and prefetching to keep GPUs busy\n",
    "- EfficientNetB0-specific normalization (built-in preprocessing layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "VAL_TEST_SPLIT = 0.3  # 70% train, 30% temp (which we split into val/test)\n",
    "\n",
    "base_kwargs = dict(\n",
    "    directory=DATASET_ROOT,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    interpolation=\"bilinear\",\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    color_mode=\"rgb\",\n",
    ")\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    **base_kwargs,\n",
    "    validation_split=VAL_TEST_SPLIT,\n",
    "    subset=\"training\",\n",
    ")\n",
    "val_test_ds = image_dataset_from_directory(\n",
    "    **base_kwargs,\n",
    "    validation_split=VAL_TEST_SPLIT,\n",
    "    subset=\"validation\",\n",
    ")\n",
    "\n",
    "val_test_cardinality = tf.data.experimental.cardinality(val_test_ds)\n",
    "val_batches = val_test_cardinality // 2\n",
    "\n",
    "def split_validation_and_test(dataset, val_batches):\n",
    "    val_dataset = dataset.take(val_batches)\n",
    "    test_dataset = dataset.skip(val_batches)\n",
    "    return val_dataset, test_dataset\n",
    "\n",
    "val_ds, test_ds = split_validation_and_test(val_test_ds, val_batches)\n",
    "\n",
    "print(f\"Train batches: {tf.data.experimental.cardinality(train_ds)}\")\n",
    "print(f\"Validation batches: {tf.data.experimental.cardinality(val_ds)}\")\n",
    "print(f\"Test batches: {tf.data.experimental.cardinality(test_ds)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomContrast(0.1),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "preprocess = keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "def prepare(ds, training=False):\n",
    "    ds = ds.cache()\n",
    "    if training:\n",
    "        ds = ds.shuffle(1000, seed=SEED)\n",
    "    ds = ds.map(lambda x, y: (preprocess(x), y), num_parallel_calls=AUTOTUNE)\n",
    "    return ds.prefetch(AUTOTUNE)\n",
    "\n",
    "train_ds_ready = prepare(train_ds, training=True)\n",
    "val_ds_ready = prepare(val_ds)\n",
    "test_ds_ready = prepare(test_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_batch(dataset, class_names, title=\"Training batch\"):\n",
    "    images, labels = next(iter(dataset.unbatch().batch(16)))\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for idx in range(min(16, images.shape[0])):\n",
    "        plt.subplot(4, 4, idx + 1)\n",
    "        plt.imshow((images[idx].numpy() + 1) / 2)  # revert preprocessing approx\n",
    "        label_idx = np.argmax(labels[idx].numpy())\n",
    "        plt.title(class_names[label_idx], fontsize=8)\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "visualize_batch(train_ds.take(1), class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350f6998",
   "metadata": {},
   "source": [
    "## Model Creation – EfficientNetB0 Backbone\n",
    "\n",
    "We fine-tune EfficientNetB0 pretrained on ImageNet. The network includes:\n",
    "\n",
    "- data augmentation and EfficientNet preprocessing\n",
    "- global average pooling + dropout (`0.2`)\n",
    "- dense classifier with L2 regularization to reduce overfitting\n",
    "- Adam optimizer (`lr=1e-3`), categorical cross-entropy loss\n",
    "- callbacks: early stopping, model checkpoint, reduce-on-plateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(num_classes: int) -> keras.Model:\n",
    "    inputs = layers.Input(shape=IMG_SIZE + (3,), name=\"input_image\")\n",
    "    x = data_augmentation(inputs)\n",
    "    x = preprocess(x)\n",
    "\n",
    "    base_model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "    base_model.trainable = False  # freeze for warm-up\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(base_model.output)\n",
    "    x = layers.Dropout(DROPOUT_RATE, name=\"dropout\")\n",
    "    outputs = layers.Dense(\n",
    "        num_classes,\n",
    "        activation=\"softmax\",\n",
    "        kernel_regularizer=regularizers.l2(L2_REG),\n",
    "        name=\"classifier\",\n",
    "    )(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"EfficientNetB0_waste\")\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\n",
    "            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.Precision(name=\"precision\"),\n",
    "            keras.metrics.Recall(name=\"recall\"),\n",
    "            keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top3_acc\"),\n",
    "        ],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_model(len(class_names))\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=5,\n",
    "    mode=\"max\",\n",
    "    restore_best_weights=True,\n",
    "    verbose=1,\n",
    ")\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1,\n",
    ")\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    MODEL_PATH,\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds_ready,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds_ready,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_history(history_obj):\n",
    "    hist = pd.DataFrame(history_obj.history)\n",
    "    metrics = [\"loss\", \"accuracy\", \"precision\", \"recall\", \"top3_acc\"]\n",
    "    fig, axes = plt.subplots(len(metrics), 1, figsize=(8, 20))\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        axes[idx].plot(hist[metric], label=f\"train_{metric}\")\n",
    "        axes[idx].plot(hist[f\"val_{metric}\"], label=f\"val_{metric}\")\n",
    "        axes[idx].set_title(metric.capitalize())\n",
    "        axes[idx].legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_history(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Optional fine-tuning: unfreeze top layers for a few more epochs (comment/uncomment as needed)\n",
    "FINE_TUNE_AT = 200  # unfreeze last 200 layers\n",
    "\n",
    "base_model = model.get_layer(\"efficientnetb0\")\n",
    "if base_model:\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-FINE_TUNE_AT]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE * 0.1),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=model.metrics,\n",
    "    )\n",
    "\n",
    "    fine_tune_history = model.fit(\n",
    "        train_ds_ready,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_ds_ready,\n",
    "        callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "    )\n",
    "else:\n",
    "    print(\"EfficientNetB0 layer not found (was model rebuilt?). Skipping fine-tuning.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf5e6e0",
   "metadata": {},
   "source": [
    "## Model Testing & Evaluation\n",
    "\n",
    "We reload the best `.h5` checkpoint and evaluate on the reserved validation/test splits. Metrics reported:\n",
    "\n",
    "- categorical accuracy & loss (from Keras evaluation)\n",
    "- precision, recall, F1 score (micro-averaged)\n",
    "- per-class precision/recall/F1 via `classification_report`\n",
    "- confusion matrix heatmap for detailed error analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model(MODEL_PATH)\n",
    "val_metrics = best_model.evaluate(val_ds_ready, verbose=0)\n",
    "test_metrics = best_model.evaluate(test_ds_ready, verbose=0)\n",
    "\n",
    "metric_names = best_model.metrics_names\n",
    "val_results = dict(zip(metric_names, val_metrics))\n",
    "test_results = dict(zip(metric_names, test_metrics))\n",
    "\n",
    "print(\"Validation metrics:\")\n",
    "for k, v in val_results.items():\n",
    "    print(f\" - {k}: {v:.4f}\")\n",
    "\n",
    "print(\"\\nTest metrics:\")\n",
    "for k, v in test_results.items():\n",
    "    print(f\" - {k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def collect_predictions(model, dataset):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for batch_images, batch_labels in dataset:\n",
    "        preds = model.predict(batch_images, verbose=0)\n",
    "        y_true.append(batch_labels.numpy())\n",
    "        y_pred.append(preds)\n",
    "    y_true = np.vstack(y_true)\n",
    "    y_pred = np.vstack(y_pred)\n",
    "    return y_true, y_pred\n",
    "\n",
    "y_true, y_pred = collect_predictions(best_model, test_ds_ready)\n",
    "y_true_labels = np.argmax(y_true, axis=1)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "precision_micro = precision_score(y_true_labels, y_pred_labels, average=\"micro\")\n",
    "recall_micro = recall_score(y_true_labels, y_pred_labels, average=\"micro\")\n",
    "f1_micro = f1_score(y_true_labels, y_pred_labels, average=\"micro\")\n",
    "\n",
    "print(f\"Micro Precision: {precision_micro:.4f}\")\n",
    "print(f\"Micro Recall: {recall_micro:.4f}\")\n",
    "print(f\"Micro F1: {f1_micro:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_labels, y_pred_labels, target_names=class_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix – Test Set\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1c89c4",
   "metadata": {},
   "source": [
    "### Single Image Testing Utility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def predict_single_image(model, image_path: str):\n",
    "    img = keras.utils.load_img(image_path, target_size=IMG_SIZE)\n",
    "    img_array = keras.utils.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess(img_array)\n",
    "    preds = model.predict(img_array)\n",
    "    top_idx = np.argmax(preds[0])\n",
    "    confidence = preds[0][top_idx]\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Pred: {class_names[top_idx]} ({confidence:.2%})\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage (update path to any image inside the dataset)\n",
    "# predict_single_image(best_model, DATASET_ROOT / \"Plastic\" / \"example.jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8707e10",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Experiment with different EfficientNet variants (B1/B2) or longer fine-tuning.\n",
    "- Add automated hyperparameter sweeps (Keras Tuner / Optuna) to optimize dropout/L2.\n",
    "- Deploy the exported `.h5` via TensorFlow Serving, FastAPI, or TF Lite for mobile robotics bins.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
